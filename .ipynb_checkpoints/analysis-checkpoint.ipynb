{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('data/reviews_temp.csv', usecols=['review_id', 'text', 'spoiler', 'movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_starwars = reviews['movie_id'] == 2488496\n",
    "starwars = reviews[is_starwars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subj_verbs = list()\n",
    "# not_stop_words = set(['i', 'you', 'he', 'she', 'it', 'we', 'they'])\n",
    "# stop_words = [word for word in nlp.Defaults.stop_words if word not in not_stop_words]\n",
    "for row, review in starwars.iterrows():\n",
    "    pairs = list()\n",
    "    doc = nlp(review.text)\n",
    "    for k, sentence in enumerate(doc.sents):\n",
    "        # print(k, sentence)\n",
    "        for token in sentence:\n",
    "            if (token.dep == nsubj or token.dep == nsubjpass) and token.head.pos == VERB:\n",
    "            # and not token.lower_ in stop_words and not token.head.lemma_.lower() in stop_words:\n",
    "                compounds = [child.lower_ for child in token.children if child.dep_ == 'compound']\n",
    "                compounds.append(token.lower_)\n",
    "                pairs.append('-'.join(compounds) + '|' + token.head.lemma_.lower())\n",
    "        # print('---')\n",
    "    subj_verbs.append(', '.join(pairs))\n",
    "    if row % 100 == 0:\n",
    "        print('Finished review ', row)\n",
    "starwars.insert(loc=4, column='subj_verb', value=subj_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = starwars['subj_verb'].tolist()\n",
    "y = starwars['spoiler'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4160, 1523)\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(tokenizer=lambda x: x.split(', '), min_df=10)\n",
    "x = vec.fit_transform(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('it|be', 8899),\n",
       " ('i|be', 3275),\n",
       " ('that|be', 2639),\n",
       " ('this|be', 2619),\n",
       " ('i|think', 1913),\n",
       " ('he|be', 1801),\n",
       " ('movie|be', 1369),\n",
       " ('i|see', 1349),\n",
       " ('i|have', 1280),\n",
       " ('they|be', 1080)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_words = x.sum(axis=0) \n",
    "word_freqs = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "word_freqs = sorted(word_freqs, key = lambda x: x[1], reverse=True)\n",
    "word_freqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_gain = dict(zip(vec.get_feature_names(), mutual_info_classif(x, y, discrete_features=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(info_gain.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6743345939022972\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma=0.3163)\n",
    "svc_scores = cross_val_score(svc, x, y, scoring='f1', cv=5)\n",
    "print(np.mean(svc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6639206649998106\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb_scores = cross_val_score(mnb, x, y, scoring='f1', cv=5)\n",
    "print(np.mean(mnb_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6062955257627902\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc_scores = cross_val_score(rfc, x, y, scoring='f1', cv=5)\n",
    "print(np.mean(rfc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6365850705394855\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_scores = cross_val_score(lr, x, y, scoring='f1', cv=5)\n",
    "print(np.mean(lr_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585621129959496\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt_scores = cross_val_score(dt, x, y, scoring='f1', cv=5)\n",
    "print(np.mean(dt_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
